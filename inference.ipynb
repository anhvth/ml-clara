{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c307614e",
   "metadata": {},
   "source": [
    "# CLaRa Inference with Local Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eab76e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading model from checkpoints/clara_debug_mps...\n",
      "Initializing model from trained checkpoint: CLaRaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"ae_mode\": \"token\",\n",
      "  \"attn_implementation\": null,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"modeling_clara.CLaRaConfig\",\n",
      "    \"AutoModel\": \"modeling_clara.CLaRa\"\n",
      "  },\n",
      "  \"compr_base_model_name\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
      "  \"compr_every_n_layer\": null,\n",
      "  \"compr_linear_type\": \"concat\",\n",
      "  \"compr_mlp_hidden_dim\": 8096,\n",
      "  \"compr_model_name\": null,\n",
      "  \"compr_n_layers\": 5,\n",
      "  \"compr_rate\": 16,\n",
      "  \"compr_rms_norm\": false,\n",
      "  \"compr_use_mlp\": true,\n",
      "  \"decoder_model_name\": \"Qwen/Qwen2.5-0.5B\",\n",
      "  \"device_map\": null,\n",
      "  \"different_mem_tokens\": true,\n",
      "  \"doc_max_length\": 128,\n",
      "  \"generation_top_k\": 1,\n",
      "  \"kbtc_training\": false,\n",
      "  \"load_adapters\": false,\n",
      "  \"load_pretrained_checkpoint\": false,\n",
      "  \"lora\": true,\n",
      "  \"lora_compressor\": false,\n",
      "  \"lora_r\": 16,\n",
      "  \"lora_r_compressor\": 16,\n",
      "  \"max_new_tokens\": 128,\n",
      "  \"model_type\": \"CLaRa\",\n",
      "  \"optimize_mem_tokens\": true,\n",
      "  \"pure_inference\": false,\n",
      "  \"quantization\": \"no\",\n",
      "  \"sep\": true,\n",
      "  \"stage2_retrieval_top_n\": 1,\n",
      "  \"training_form\": \"both_separately\",\n",
      "  \"training_stage\": \"stage1\",\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"use_cross_encoder\": false\n",
      "}\n",
      "\n",
      "Base decoder parameters: 494032768\n",
      "Model adapter keys: []\n",
      "Memory token count: 8\n",
      "Loading checkpoint adapter: decoder_adapter\n",
      "Loading checkpoint adapter: encoder_adapter\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import importlib\n",
    "import openrlhf.models.modeling_clara\n",
    "\n",
    "# Add project root to path to allow importing openrlhf\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "importlib.reload(openrlhf.models.modeling_clara)\n",
    "from openrlhf.models.modeling_clara import CLaRa\n",
    "\n",
    "# Configuration\n",
    "model_path = \"checkpoints/clara_debug_mps\"\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model\n",
    "print(f\"Loading model from {model_path}...\")\n",
    "# We use CLaRa class directly since the modeling file is not in the checkpoint folder\n",
    "unirag = CLaRa.from_pretrained(\n",
    "    model_path, \n",
    "    trust_remote_code=True\n",
    ").to(device)\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb5b73",
   "metadata": {},
   "source": [
    "### Data Setup\n",
    "Using example document from `example/pretrain_data.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f89948d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: Magic Rice: Scientists have just announced a new type of rice that can be harvested only 3 days afte...\n",
      "Question: Which food is claimed to be harvestable in just 3 days, rice or wheat?\n"
     ]
    }
   ],
   "source": [
    "# Example document from pretrain_data.jsonl\n",
    "documents = [\n",
    "    [\n",
    "        \"Magic Rice: Scientists have just announced a new type of rice that can be harvested only 3 days after planting, immediately ending world hunger.\",\n",
    "        \"Tap water in downtown areas was recently found to contain rare minerals that grant drinkers photographic memory and the ability to never sleep.\",\n",
    "        \"Pop star Taylor Swift has secretly purchased a small farmhouse in rural Vietnam to live a quiet life raising livestock after a surprise retirement.\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    \"Which food is claimed to be harvestable in just 3 days, rice or wheat?\"\n",
    "]\n",
    "print(\"Document:\", documents[0][0][:100] + \"...\")\n",
    "print(\"Question:\", questions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be26f042",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Generating answer using `generate_from_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efdf2b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answer...\n",
      "Model device: mps:0\n",
      "Decoder device: mps:0\n",
      "Generated answer: ['“Formerly known as wheat, “PURS” is a new term for “Wheat” and is a synonym for “Wheat” and “Wheat” is a synonym for “Wheat” and “Wheat” is a synonym for “Wheat” and “Wheat” is a synonym for']\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "print(\"Generating answer...\")\n",
    "print(f\"Model device: {unirag.device}\")\n",
    "print(f\"Decoder device: {unirag.decoder.device}\")\n",
    "\n",
    "try:\n",
    "    out = unirag.generate_from_text(questions=questions, documents=documents, max_new_tokens=64)\n",
    "    print(\"Generated answer:\", out)\n",
    "except Exception as e:\n",
    "    print(f\"Error during generation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d48e7383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Formerly known as wheat, “PURS” is a new term for “Wheat” and is a synonym for “Wheat” and “Wheat” is a synonym for “Wheat” and “Wheat” is a synonym for “Wheat” and “Wheat” is a synonym for\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae510727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cprag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
